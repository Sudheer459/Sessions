Playbook - Keep all your modules in a single file with YAML syntax.

A Terraform module is a collection of standard configuration files in a dedicated directory. 

A Kubernetes manifest file is a YAML or JSON file that describes the desired state of a Kubernetes object in a cluster.


Pipeline Syntax

Pipeline{
	agent{
		label 'java-agent'
	}
	options{
		timeout(time:30, unit: 'MINUTES')
	}
	Environment{
		Greeting = 'Hello World'
	}
	stages{
		stage('Build'){
			steps{
				sh 'echo this is build'
			}
		
		}
		post{
		 always{
		 }
		 success{
		 }
		 failure{
		 }
	}
}

----------------
kind: Pod
apiVersion: v1
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:stable-otel
-----------------------

Using Jenkins and its shared libraries you have ensured that your application code is bug-free and secure too.
Later on you build the image and push the image to a private ECR using Docker.
Then using terraform you have created the necessary infrastructure such as a VPC, SGs, EKS, ALB, RDS, ACM, 
Workstation etc for your application deployment.
At last you have deployed the application to the EKS cluster.
Hope this gives you a better understanding of how to integrate all the tools together.
----------------
Devops pipeline stages... PCBTRMO
Plan, code, build, test, release, monitor, operate
--------------------
Devops pipeline process..
SCM
Build Automation
Automated Testing
Deployment Automation
---------------------------
Here are all the tools commonly used in DevOps across various industries:

1)Cloud Computing: AWS â˜ï¸
2)Version Control: Git ðŸ“
3)Pipelines: Jenkins ðŸš€
4)Configuration Management: Ansible ðŸ”©
5)Containerization: Docker ðŸ³
6)Container Orchestration: Kubernetes (K8S) â˜¸ï¸
7)Monitoring and Logging: Prometheus ðŸ“Š
8)Infrastructure as Code: Terraform ðŸŒ

These tools help streamline the DevOps process, making software development, deployment, and 
management more efficient and effective.
-------------
Prometheus

Cloud Environment: Prometheus should find the nodes automatically and add them to scrape list

Service Discovery:
---------------------
 Underlying nodes should have node exporter installed and started

Describe ec2 instances ---> listing ec2 instances---> get the IP address

filter using tags, Monitoring -- true 

if value < 1, then raise the alert

1. raise the alert
2. manage the alert

2 types of metrics
counter and Gauge

Latency
errors
traffic
saturation --> Prometheus

ELK -- Elastic kibana logstash
----------------
Elasticsearch --> repository,which stores something.. logs storage..DB application

KIbana ---> Visualisation/UI tool for elasticsearch 

Logstash: Filtering the logs before storing to elasticsearch.

Scheduler --- Scheduler schedules the pod

Daemon set :: Daemonset will make sure a pod runs in every node.

etcd: entire k8 cluster data is in etcd.

kube-proxy --> on behalf of someone. it intercepts every incoming and outgoing request of node.
 kube-proxy maintains network rules on nodes. these network rules allow network communication to your Pods

kubelet --> it connects nodes to control plane. An agent that runs on each node in the cluster.
 it pulls the information from control plane and runs the pods.
 
 -------------
 Below Errors..

imagePullBackOff --> your k8s node is unable to pull the image
(Version is wrong,repository name r address,Connection cut issue/network. We have to check image address)

crashLoopBackoff --> pod is not able to run... if Backend is not able to connect DB
(crash... we need to check logs)

pending --> PV and PVC setup and config are not proper. pod is not able to mount the volume.
(We have to describe and check logs)
 -----------------------------
 
 

Containers best practices
---
1. Without root user
2. use volumes
3. Use official images
4. Use small images, dont keep unnecessary installations
5. use multi stage builds
6. use health checks
7. use custom network
8. reduce image layers

----------------------
Cluster upgrade is planned
----------------------
No downtime to the existing applications but no new release and no new deployments in the upgrade time.

Communications sent about cluster upgrade activity is started.

1. First we need to get another node group called green.
2. Taint the green nodes, so that they should not get any pods scheduled.

3. Now upgrade your control plane

If any issues in control plane/EKS then you are able to access your application or not?
There is no relation b/w application and EKS if any issue also we can access 
because LB always connected to nodegroup. Unless nodes are down no issue for application

4. upgrade green node group also to 1.30
5. Shift workloads from 1.29 node group to 1.30 node group
6. Taint blue nodes(cordon blue nodes)
7. Untaint green nodes
8. Drain blue nodes

Inform all stake holders, applications teams. Perform sanity checks/testing(Application team will do)
close the acivity.



