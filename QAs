Scenario: Developing a new login feature for an application.
1. Create a Feature Branch:
Developer creates a new branch for the login feature.
git checkout develop
git checkout -b feature/login
Work on the Feature:
2. Developer works on the login feature, making several commits.
git add .
git commit -m "Add login form"
git add .
git commit -m "Implement authentication"
Push the Branch and Open a Pull Request:
3. Developer pushes his branch to GitHub and opens a pull request.
git push origin feature/login
he then opens a pull request on GitHub from feature/login to develop.
4. Review and Merge the Pull Request:
Team members review the pull request, suggest changes, and approve it.
The pull request is merged into the develop branch on GitHub.
5. Create a Release Branch:
When the develop branch is ready for release, a release branch is created.
git checkout develop
git checkout -b release/1.0.0
6. Prepare for Release:
The team tests the release branch, fixes bugs, and makes final adjustments.
git add .
git commit -m "Fix bugs for release"
7. Merge Release Branch into Main and Develop:
Once the release is stable, the release branch is merged into both main and develop.
git checkout main
git merge release/1.0.0
git checkout develop
git merge release/1.0.0
-----

1. if we have prometheus in one server and grafana in another one. 
if we mention the prometheus IP in grafana UI to get the data.
What if the grafana server is down, how to do we configure to auto fetch the IP address when its recreated.

Ans::  I think creating r53 record of the server and providing it within the configuration,
 will avoid the issue. Please let me know your thoughts on this..


2. service-discovery will identify the new nodes every time and add them to prometheus to get monitored
But how can we automate the installation of node_exporter agent in nodes when they created automatically 
as part of auto-scaling or replication etc.

Ans:: we can use ansible-playbook to automatically configure and deploy node_export on new nodes.
 (or) you can attach user data script like install node_exporter, create systemd service,
 reload and start node_exporter this script you can attach autoscalling group launch templates, 
 whenever new instance created ensuring run the script on start up

2. Where do you keep secrets in Jenkins?
5. After Terraform apply you are experiencing slowness, how do you trobleshoot?
11. If the deployment fails how do you rollback in Jenkins?

-----------------
1. How to backup Jenkins?
From the main menu select Manage Jenkins, then go to Plugins>Available and search for backup

2. Where do you keep secrets in Jenkins?
In Jenkins, secrets are typically stored and managed in a secure way,
Jenkins Credentials Store:
Jenkins Credentials Plugin: Jenkins has a built-in credentials management
 system where you can store secrets like passwords, SSH keys, API tokens, and more.
 These credentials can be used in Jenkins pipelines or jobs without 
 exposing them in the job configuration or pipeline scripts.
Types of Credentials:
Username with Password: Store username and password securely.
SSH Username with Private Key: Store SSH keys securely.
Secret Text: Store arbitrary secret text, such as API tokens.
Secret File: Store secret files, such as service account keys.

3. What is Terraform import?
Terraform import is a Terraform CLI command used to read real-world infrastructure
 and update its state so that future updates to the same set of infrastructure
 can be applied via Infrastructure as Code (IaC)


4. Distinguish between Terraform init, Terraform validate and Terraform apply?
Initialize terraform::
Terraform init - terraform will check for providers. It will download AWS providers and keep them.
Terraform plan - terraform will show what are the resources it is going to create.

Validate syntax, if correct then it will show the resources, it will create

.gitignore file = do not push to git repository


5. After Terraform apply you are experiencing slowness, how do you trobleshoot?
Ans:
Experiencing slowness after running a terraform apply could be related to various factors, including infrastructure, Terraform configuration, or the environment itself.
1.Check Terraform Logs.
2.Examine Infrastructure Resources.
3.Evaluate Network Latency.
4.Check for API Rate Limits.
5.Inspect Resource Dependencies.
6.Review Terraform Configuration.
7.Analyze System Resources.
8.Check for External Dependencies.
9.Consult Cloud Provider Metrics.
10.Rollback and Reapply Incrementally.


6. I want to create static website in docker. Which instruction you use?
	Install Docker on your local machine if you haven't already. 
Navigate to your project's root directory in the terminal. 
Run docker build -t my-static-website . to build the Docker image. 
Run docker run -p 8080:80 my-static-website to start a local instance of your website on port 8080.

7. configmap and secrets in Kubernetes?
ConfigMaps are typically used for non-sensitive configuration data, 
while Secrets are used for storing sensitive information. 
ConfigMaps stores data as key-value pairs, 
whereas Secrets stores data as base64-encoded data,
 thereby ensuring an additional layer of security.
 
 
8. Diff ALB and Network load balancer?

9. How do you host one application in multiple servers using Jenkins?
you will require a Product called Deployer installed on one of your instances and 
define all possible target servers (and target groups) there. 
After the servers are defined you can install the WmDeployerResource package from there to the targets.

		rrrrr
install ansible on the jenkins-agent. pip install ansible or apt install ansible.
Load your ssh key into Jenkins credentials store.
 I assume here that you use the credential store plugin 
 (but you could also load it into an ssh-agent, or use some other method to expose the key on the jenkins-agents.)

10. Statefulset and Daemonset?
StatefulSet -->>> Used for stateful applications i.e., which should have some storage.

Daemonset will make sure a pod runs in every node. why this is useful?
we have to access underlying node logs and push them to elastic search for log monitoring. 
if we run deamonset in kubernetes, it make sure a pod is automatically created when new node is added.


11. If the deployment fails how do you rollback in Jenkins?
Ans:
Rolling back a deployment in Jenkins after a failure depends on the deployment strategy and the tools you use for deployment.
1.Use a Version Control-Based Rollback.
2.Use Built-In Rollback Mechanisms of Deployment Tools.
3.Implement Blue-Green or Canary Deployments.
4.Artifact-Based Rollback.
5.Automated Rollback Script.
6.Using Jenkins Pipeline for Rollback.
7.Manual Intervention.
8.Use of Feature Flags.
9.Database Rollbacks.
Jenkins pipeline has robust rollback mechanisms to quickly recover from deployment failures.

12. If the pod crashes continuously how do you troubleshoot?
If one of the containers in the Pod fails, then Kubernetes may try to restart that specific container. 

Run the kubectl describe pod [name] command for the problematic pod. 
The output of this command will indicate the root cause of the issue. 
This can be one of the following: Wrong image name or tagâ€”this typically 
happens because the image name or tag was typed incorrectly in the pod manifest.



13. If a container is consuming more memory in Kubernetes how will you trobleshoot?
If a Container allocates more memory than its limit, the Container becomes a candidate for termination. 
If the Container continues to consume memory beyond its limit, the Container is terminated.
---------------------
1) If Jenkins master got crashed, what will happened to nodes, whether the jobs run properly 
 and how can we recover the master

1.If a Jenkins master crashes, it will impact the Jenkins nodes (agents) in the following ways:
1.Jobs Execution.
2.communication.
3.Build Artifacts and Logs.
Recovering the Jenkins Master:
1.Restore from Backup.
2.Using High Availability (HA)
3.Cloud-based Recovery.
4.Manual Recovery.
Preventive Measures:
1.Regular Backups.
2.HA Setup.
3.Automated Backups.
4.Monitoring.


2) In AWS Account A how can he access the  S3 of the Account B
To allow AWS Account A to access an S3 bucket in AWS Account B, 
you need to set up a cross-account access policy using IAM roles and bucket policies.
1.Account B creates an IAM role allowing Account A to assume it and grants the necessary S3 permissions.
2.Account B updates the S3 bucket policy to allow the role from Account A to access the bucket.
3.Account A assumes the role and uses the temporary credentials to access the S3 bucket in Account B.
cross-account access policy:
A cross-account policy in AWS allows one AWS account to access resources
 (like S3 buckets, EC2 instances, etc.) in another AWS account.
Cross-account policy means resource-based policy
------------------------------------

How do `ğ—´ğ—¶ğ˜ ğ—ºğ—²ğ—¿ğ—´ğ—²` and `ğ—´ğ—¶ğ˜ ğ—¿ğ—²ğ—¯ğ—®ğ˜€ğ—²` differ?

Merging
---------
create another branch
do the changes in that branch
raise PR
get the approval
then merge it

merge gives us a new merge which has 2 parents, we can clearly see the history

Rebase
---------
rebase --> change the base
no extra commit
commit id are changed
no history is preserved, it is rewritten as if it is done in main branch
looks clean, linear history

single branch --> multiple persons are working --> prefer merge
if you want to keep the history --> prefer merge
blindly go for merge, if you are not sure

single branch --> single person --> prefer rebase
if you dont want history --> prefer rebase
if you want clean structure --> prefer rebase

 What is the purpose of `.ğ—´ğ—¶ğ˜ğ—¶ğ—´ğ—»ğ—¼ğ—¿ğ—²`?
.gitignore file = do not push to git repository

6. How do `ğ—´ğ—¶ğ˜ ğ—¿ğ—²ğ˜€ğ—²ğ˜` and `ğ—´ğ—¶ğ˜ ğ—¿ğ—²ğ˜ƒğ—²ğ—¿ğ˜` differ?

Reset will undo the changes, it is destructive operation. It will change the history and commit id.

git reset

1. soft - reset the commit, but keep the changes in staging area.
2. mixed - reset the commit, but will not keep the changes in staging area.
3. hard - reset the commit, changes will be reset from workspace, staging area and commit.


Revert..
Changes are pushed to remote, others pulled your changes already.
reset is not recommended if changes are already pushed to remote.

Revert is safe if changes are pushed to remote already. revert will not change the history 

Mistakes should not removed from history, it should only be corrected.


7. How do `ğ—´ğ—¶ğ˜ ğ—³ğ—²ğ˜ğ—°ğ—µ` and `ğ—´ğ—¶ğ˜ ğ—½ğ˜‚ğ—¹ğ—¹` differ?

git pull" automatically merges the fetched changes into the current branch, while "git fetch" does not. 
This makes "git pull" a more convenient command if you want to quickly update your local branch with changes from the remote repository.


9. How do you check the ğ—±ğ—¶ğ—³ğ—³ğ—²ğ—¿ğ—²ğ—»ğ—°ğ—²ğ˜€ between ğ˜ğ˜„ğ—¼ ğ—°ğ—¼ğ—ºğ—ºğ—¶ğ˜ğ˜€ in Git?
 git diff $(git merge-base A HEAD) 

10. How do you check the ğ˜€ğ˜ğ—®ğ˜ğ˜‚ğ˜€ of the ğ˜„ğ—¼ğ—¿ğ—¸ğ—¶ğ—»ğ—´ ğ—±ğ—¶ğ—¿ğ—²ğ—°ğ˜ğ—¼ğ—¿ğ˜† in Git?

How do you check the ğ˜€ğ˜ğ—®ğ˜ğ˜‚ğ˜€ of the ğ˜„ğ—¼ğ—¿ğ—¸ğ—¶ğ—»ğ—´ ğ—±ğ—¶ğ—¿ğ—²ğ—°ğ˜ğ—¼ğ—¿ğ˜† in Git?
Ans:
To check the status of the working directory in Git, you can use the git status command. This command provides a summary of the current state of your working directory and the staging area, showing which files are modified, staged for commit, or untracked.

How do you handle and resolve ğ—–ğ—£ğ—¨-ğ—¿ğ—²ğ—¹ğ—®ğ˜ğ—²ğ—± tickets?
Ans:
Handling and resolving CPU-related tickets typically involves a series of steps to identify the root cause of high CPU usage and take appropriate actions to mitigate the issue. Hereâ€™s a structured approach to managing and resolving such tickets:
1. Gather Information.
2. Identify the Cause of High CPU Usage.
3. Analyze and Diagnose the Problem.
4. Take Corrective Actions.
5. Implement Long-term Solutions.
6. Document and Communicate.
7. Follow Up and Prevent Recurrence


Where do you configure ğ——ğ—¼ğ—°ğ—¸ğ—²ğ—¿ ğ—›ğ˜‚ğ—¯ credentials and ğ—¥ğ——ğ—¦ credentials?
Ans:
Configuring Docker Hub credentials and RDS (Relational Database Service) credentials securely is essential to ensure that your applications and infrastructure can access these services without exposing sensitive information. Below are the best practices for configuring these credentials:
1. Docker Hub Credentials Configuration:
a. Docker CLI Login.
b. Docker Secret (For Swarm Mode).
c. Environment Variables (CI/CD Pipelines).
d. Credential Helper (Kubernetes with Kubernetes Secrets).
2. RDS Credentials Configuration:
a. Environment Variables.
b. AWS Systems Manager Parameter Store or Secrets Manager.
c. IAM Roles and RDS IAM Authentication.
d. Kubernetes Secrets (If Using Kubernetes).


As the role DevOps engineer working with a few developers, how do you ğ—°ğ—¼ğ—¹ğ—¹ğ—®ğ—¯ğ—¼ğ—¿ğ—®ğ˜ğ—² and ğ—ºğ—®ğ—»ğ—®ğ—´ğ—² ğ˜ğ—®ğ˜€ğ—¸ğ˜€?
Ans:
As a DevOps engineer working with a few developers, effective collaboration and task management are key to ensuring smooth operations and project success. Here are strategies to help you collaborate and manage tasks effectively:
1. Establish Clear Communication Channels.
2. Define Clear Roles and Responsibilities.
3. Implement Effective Task Management.
4. Automate Where Possible.
5. Use Version Control Best Practices.
6. Foster a Collaborative Culture.
7. Plan for Scalability and Flexibility.
8. Maintain Transparency and Documentation.




What are ğ——ğ—¼ğ—°ğ—¸ğ—²ğ—¿ğ—³ğ—¶ğ—¹ğ—²ğ˜€ and ğ—½ğ—¶ğ—½ğ—²ğ—¹ğ—¶ğ—»ğ—²ğ˜€? How are they used in ğ—–ğ—œ/ğ—–ğ——?
Ans:
Dockerfiles:
Dockerfiles are text files that contain a series of instructions on how to build a Docker image. These instructions define the environment, the application code, and all dependencies required to run the application inside a Docker container. A Dockerfile allows you to automate the creation of Docker images, ensuring consistency across different environments.
Usage in CI/CD:
In CI/CD, Dockerfiles are used to build consistent and reproducible Docker images as part of the build process. Hereâ€™s how they are commonly used:
1 Build Step.
2. Testing.
3. Deployment.
Pipelines:
Pipelines refer to automated workflows in CI/CD that define a series of stages or steps required to build, test, and deploy an application. Each stage in the pipeline is a sequence of tasks that need to be executed in a specific order. Pipelines enable continuous integration and continuous deployment, automating the process from code commit to production deployment.
Usage in CI/CD:
Continuous Integration (CI).
Continuous Delivery (CD).
Feedback Loop.


Where should ğ—¡ğ—²ğ˜…ğ˜‚ğ˜€ credentials be stored securely?
Ans:
Nexus credentials, like any sensitive information, should be stored securely to prevent unauthorized access. Here are some best practices for securely storing Nexus credentials:
1. Environment Variables.
2. Secrets Management Tools.
3. CI/CD Tool Secrets.
4. Configuration Management Tools.
5. Kubernetes Secrets.
6. Avoid Hardcoding Credentials.
7. Access Controls and Audit Logging.



What is ğ— ğ—®ğ˜ƒğ—²ğ—», and what are its primary uses?
Ans:
Maven is a powerful build automation and project management tool used primarily for Java projects. Developed by the Apache Software Foundation, Maven uses a declarative XML-based configuration called pom.xml (Project Object Model) to manage a project's build, dependencies, and overall project lifecycle.
Primary Uses of Maven:
Build Automation.
Dependency Management.
Project Management.
Consistent Project Configuration.
Plugin System.
Build Lifecycle Management.
Reproducible Builds.
Site Generation and Reporting.
Integration with CI/CD Pipelines.


How do you ğ—¶ğ—´ğ—»ğ—¼ğ—¿ğ—² certain ğ—³ğ—¶ğ—¹ğ—²ğ˜€ while creating a ğ——ğ—¼ğ—°ğ—¸ğ—²ğ—¿ğ—³ğ—¶ğ—¹ğ—²?
Ans:
To ignore certain files or directories while creating a Docker image using a Dockerfile, you can use a special file called .dockerignore. This file works similarly to a .gitignore file, specifying patterns that match files and directories that should be excluded from the Docker build context.

-------------------------